{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e4013dd-40d5-4b09-bda0-07b76a5cfe6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Case 1 : Product is available and the customer care agent can help  with the quantity/ product information depending on the interaction with the customer\n",
    "# Case 2 : Product is not available. Recommendation system will top 5 similar products  which are available in store along with product information and on hand quantity if required. So will help the customer agent to pitch the customer\n",
    "# Allied products - Upselling - Applicable for both case 1 and 2\n",
    "# Based on location information , we can recommend the closest store which will have the exact product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be7622a2-34ae-4cf7-8b62-7c3e64d971cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Assumptions - to be included\n",
    "# real time inventory data is not included -\n",
    "# We can't provide assurance if the requested quantity by the customer will be fullfilled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b35a280c-70b6-463b-bdbe-b8fd30e396dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting databricks-genai-inference\n  Downloading databricks_genai_inference-0.2.3-py3-none-any.whl (17 kB)\nCollecting pyyaml>=5.4.1\n  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 705.5/705.5 kB 13.4 MB/s eta 0:00:00\nCollecting tenacity==8.2.3\n  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\nCollecting databricks-sdk==0.19.1\n  Downloading databricks_sdk-0.19.1-py3-none-any.whl (447 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 447.8/447.8 kB 49.9 MB/s eta 0:00:00\nCollecting httpx<1,>=0.23.0\n  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.6/75.6 kB 10.3 MB/s eta 0:00:00\nCollecting typing-extensions>=4.7.1\n  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\nCollecting pydantic>=2.4.2\n  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.3/409.3 kB 42.0 MB/s eta 0:00:00\nRequirement already satisfied: requests<3,>=2.26.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-genai-inference) (2.28.1)\nCollecting google-auth~=2.0\n  Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 189.2/189.2 kB 26.1 MB/s eta 0:00:00\nRequirement already satisfied: idna in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->databricks-genai-inference) (3.4)\nCollecting httpcore==1.*\n  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.9/77.9 kB 11.8 MB/s eta 0:00:00\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->databricks-genai-inference) (3.5.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->databricks-genai-inference) (2022.12.7)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->databricks-genai-inference) (1.2.0)\nCollecting h11<0.15,>=0.13\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 9.4 MB/s eta 0:00:00\nCollecting pydantic-core==2.18.2\n  Downloading pydantic_core-2.18.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 74.7 MB/s eta 0:00:00\nCollecting annotated-types>=0.4.0\n  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.26.0->databricks-genai-inference) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.26.0->databricks-genai-inference) (1.26.14)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 23.9 MB/s eta 0:00:00\nCollecting pyasn1<0.7.0,>=0.4.6\n  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.3/85.3 kB 9.1 MB/s eta 0:00:00\nInstalling collected packages: typing-extensions, tenacity, pyyaml, pyasn1, h11, cachetools, annotated-types, rsa, pydantic-core, pyasn1-modules, httpcore, pydantic, httpx, google-auth, databricks-sdk, databricks-genai-inference\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 8.1.0\n    Not uninstalling tenacity at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'tenacity'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'pydantic'. No files were found to uninstall.\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.1.6\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\nSuccessfully installed annotated-types-0.6.0 cachetools-5.3.3 databricks-genai-inference-0.2.3 databricks-sdk-0.19.1 google-auth-2.29.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.7.1 pydantic-core-2.18.2 pyyaml-6.0.1 rsa-4.9 tenacity-8.2.3 typing-extensions-4.11.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: typing_extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (4.11.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting mlflow\n  Downloading mlflow-2.12.1-py3-none-any.whl (20.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.2/20.2 MB 40.4 MB/s eta 0:00:00\nCollecting querystring-parser<2\n  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nCollecting graphene<4\n  Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 19.4 MB/s eta 0:00:00\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.1.1)\nCollecting markdown<4,>=3.3\n  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.4/105.4 kB 16.2 MB/s eta 0:00:00\nCollecting gitpython<4,>=3.1.9\n  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 28.5 MB/s eta 0:00:00\nCollecting sqlalchemy<3,>=1.4.0\n  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 95.2 MB/s eta 0:00:00\nCollecting gunicorn<22\n  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.2/80.2 kB 12.3 MB/s eta 0:00:00\nCollecting sqlparse<1,>=0.4.0\n  Downloading sqlparse-0.5.0-py3-none-any.whl (43 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.0/44.0 kB 6.8 MB/s eta 0:00:00\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.0)\nCollecting docker<8,>=4.0.0\n  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.6/147.6 kB 20.1 MB/s eta 0:00:00\nRequirement already satisfied: pyyaml<7,>=5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (6.0.1)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.10.0)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.5.3)\nCollecting alembic!=1.10.0,<2\n  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.4/233.4 kB 29.9 MB/s eta 0:00:00\nRequirement already satisfied: pytz<2025 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2022.7)\nRequirement already satisfied: protobuf<6,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (4.24.0)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (2.28.1)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.23.5)\nRequirement already satisfied: packaging<25 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (23.2)\nCollecting cloudpickle<4\n  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (0.4)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.7.0)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/lib/python3/dist-packages (from mlflow) (4.6.4)\nCollecting Flask<4\n  Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 12.9 MB/s eta 0:00:00\nCollecting Mako\n  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.8/78.8 kB 12.2 MB/s eta 0:00:00\nRequirement already satisfied: typing-extensions>=4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.14)\nCollecting itsdangerous>=2.1.2\n  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nCollecting blinker>=1.6.2\n  Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\nCollecting click<9,>=7.0\n  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 8.5 MB/s eta 0:00:00\nCollecting Werkzeug>=3.0.0\n  Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 227.3/227.3 kB 24.9 MB/s eta 0:00:00\nCollecting gitdb<5,>=4.0.1\n  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 11.1 MB/s eta 0:00:00\nCollecting graphql-core<3.3,>=3.1\n  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 202.9/202.9 kB 27.8 MB/s eta 0:00:00\nCollecting aniso8601<10,>=8\n  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 8.4 MB/s eta 0:00:00\nCollecting graphql-relay<3.3,>=3.1\n  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.1)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.0.5)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.4.0)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.4)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nCollecting greenlet!=0.4.17\n  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 616.0/616.0 kB 54.7 MB/s eta 0:00:00\nCollecting smmap<6,>=3.0.1\n  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\nInstalling collected packages: aniso8601, Werkzeug, sqlparse, smmap, querystring-parser, markdown, Mako, itsdangerous, gunicorn, greenlet, graphql-core, cloudpickle, click, blinker, sqlalchemy, graphql-relay, gitdb, Flask, docker, graphene, gitpython, alembic, mlflow\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'blinker'. No files were found to uninstall.\nSuccessfully installed Flask-3.0.3 Mako-1.3.3 Werkzeug-3.0.3 alembic-1.13.1 aniso8601-9.0.1 blinker-1.8.2 click-8.1.7 cloudpickle-3.0.0 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 greenlet-3.0.3 gunicorn-21.2.0 itsdangerous-2.2.0 markdown-3.6 mlflow-2.12.1 querystring-parser-1.2.4 smmap-5.0.1 sqlalchemy-2.0.30 sqlparse-0.5.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting tiktoken\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 24.5 MB/s eta 0:00:00\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.10/site-packages (from tiktoken) (2.28.1)\nCollecting regex>=2022.1.18\n  Downloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 774.1/774.1 kB 61.2 MB/s eta 0:00:00\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\nInstalling collected packages: regex, tiktoken\nSuccessfully installed regex-2024.4.28 tiktoken-0.6.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting dbdemos\n  Downloading dbdemos-0.3.61-py3-none-any.whl (41.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.1/41.1 MB 20.4 MB/s eta 0:00:00\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from dbdemos) (1.5.3)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from dbdemos) (2.28.1)\nCollecting dbsqlclone\n  Downloading dbsqlclone-0.1.24-py3-none-any.whl (11 kB)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->dbdemos) (2.8.2)\nRequirement already satisfied: numpy>=1.21.0 in /databricks/python3/lib/python3.10/site-packages (from pandas->dbdemos) (1.23.5)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->dbdemos) (2022.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->dbdemos) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->dbdemos) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->dbdemos) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->dbdemos) (3.4)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->dbdemos) (1.16.0)\nInstalling collected packages: dbsqlclone, dbdemos\nSuccessfully installed dbdemos-0.3.61 dbsqlclone-0.1.24\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting databricks-vectorsearch\n  Downloading databricks_vectorsearch-0.33-py3-none-any.whl (13 kB)\nCollecting mlflow-skinny<3,>=2.11.3\n  Downloading mlflow_skinny-2.12.1-py3-none-any.whl (5.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 53.2 MB/s eta 0:00:00\nCollecting requests>=2\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 9.0 MB/s eta 0:00:00\nCollecting protobuf<5,>=3.12.0\n  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.6/294.6 kB 35.4 MB/s eta 0:00:00\nCollecting click<9,>=7.0\n  Using cached click-8.1.7-py3-none-any.whl (97 kB)\nCollecting gitpython<4,>=3.1.9\n  Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\nCollecting pytz<2025\n  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 505.5/505.5 kB 49.8 MB/s eta 0:00:00\nCollecting entrypoints<1\n  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\nCollecting sqlparse<1,>=0.4.0\n  Using cached sqlparse-0.5.0-py3-none-any.whl (43 kB)\nCollecting packaging<25\n  Downloading packaging-24.0-py3-none-any.whl (53 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 6.4 MB/s eta 0:00:00\nCollecting pyyaml<7,>=5.1\n  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\nCollecting importlib-metadata!=4.7.0,<8,>=3.7.0\n  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\nCollecting cloudpickle<4\n  Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.7-py3-none-any.whl (66 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.8/66.8 kB 11.0 MB/s eta 0:00:00\nCollecting charset-normalizer<4,>=2\n  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.1/142.1 kB 20.7 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 20.9 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.1/121.1 kB 19.5 MB/s eta 0:00:00\nCollecting gitdb<5,>=4.0.1\n  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\nCollecting smmap<6,>=3.0.1\n  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\nInstalling collected packages: pytz, zipp, urllib3, sqlparse, smmap, pyyaml, protobuf, packaging, idna, entrypoints, cloudpickle, click, charset-normalizer, certifi, requests, importlib-metadata, gitdb, gitpython, mlflow-skinny, databricks-vectorsearch\n  Attempting uninstall: pytz\n    Found existing installation: pytz 2022.7\n    Not uninstalling pytz at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'pytz'. No files were found to uninstall.\n  Attempting uninstall: zipp\n    Found existing installation: zipp 1.0.0\n    Not uninstalling zipp at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'zipp'. No files were found to uninstall.\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.14\n    Not uninstalling urllib3 at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'urllib3'. No files were found to uninstall.\n  Attempting uninstall: sqlparse\n    Found existing installation: sqlparse 0.5.0\n    Uninstalling sqlparse-0.5.0:\n      Successfully uninstalled sqlparse-0.5.0\n  Attempting uninstall: smmap\n    Found existing installation: smmap 5.0.1\n    Uninstalling smmap-5.0.1:\n      Successfully uninstalled smmap-5.0.1\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0.1\n    Uninstalling PyYAML-6.0.1:\n      Successfully uninstalled PyYAML-6.0.1\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.24.0\n    Not uninstalling protobuf at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'protobuf'. No files were found to uninstall.\n  Attempting uninstall: packaging\n    Found existing installation: packaging 23.2\n    Not uninstalling packaging at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'packaging'. No files were found to uninstall.\n  Attempting uninstall: idna\n    Found existing installation: idna 3.4\n    Not uninstalling idna at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'idna'. No files were found to uninstall.\n  Attempting uninstall: entrypoints\n    Found existing installation: entrypoints 0.4\n    Not uninstalling entrypoints at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'entrypoints'. No files were found to uninstall.\n  Attempting uninstall: cloudpickle\n    Found existing installation: cloudpickle 3.0.0\n    Uninstalling cloudpickle-3.0.0:\n      Successfully uninstalled cloudpickle-3.0.0\n  Attempting uninstall: click\n    Found existing installation: click 8.1.7\n    Uninstalling click-8.1.7:\n      Successfully uninstalled click-8.1.7\n  Attempting uninstall: charset-normalizer\n    Found existing installation: charset-normalizer 2.0.4\n    Not uninstalling charset-normalizer at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'charset-normalizer'. No files were found to uninstall.\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2022.12.7\n    Not uninstalling certifi at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'certifi'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.28.1\n    Not uninstalling requests at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.6.4\n    Not uninstalling importlib-metadata at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56\n    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n  Attempting uninstall: gitdb\n    Found existing installation: gitdb 4.0.11\n    Uninstalling gitdb-4.0.11:\n      Successfully uninstalled gitdb-4.0.11\n  Attempting uninstall: gitpython\n    Found existing installation: GitPython 3.1.43\n    Uninstalling GitPython-3.1.43:\n      Successfully uninstalled GitPython-3.1.43\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbotocore 1.27.96 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.1 which is incompatible.\nSuccessfully installed certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 cloudpickle-3.0.0 databricks-vectorsearch-0.33 entrypoints-0.4 gitdb-4.0.11 gitpython-3.1.43 idna-3.7 importlib-metadata-7.1.0 mlflow-skinny-2.12.1 packaging-24.0 protobuf-4.25.3 pytz-2024.1 pyyaml-6.0.1 requests-2.31.0 smmap-5.0.1 sqlparse-0.5.0 urllib3-2.2.1 zipp-3.18.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install databricks-genai-inference\n",
    "%pip install --upgrade typing_extensions\n",
    "%pip install mlflow\n",
    "%pip install tiktoken\n",
    "%pip install dbdemos\n",
    "%pip install --upgrade --force-reinstall databricks-vectorsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d522eada-c930-4c73-9d31-b10832f3e9b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (2.12.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (2.0.30)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (0.5.0)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (8.1.7)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (3.3)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (3.1.43)\nRequirement already satisfied: packaging<25 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (24.0)\nRequirement already satisfied: requests<3,>=2.17.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (2.31.0)\nRequirement already satisfied: pyyaml<7,>=5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (6.0.1)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (7.1.0)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.1.1)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (3.6)\nRequirement already satisfied: pytz<2025 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (2024.1)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.23.5)\nRequirement already satisfied: cloudpickle<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (3.0.0)\nRequirement already satisfied: querystring-parser<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (8.0.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.10.0)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (1.13.1)\nRequirement already satisfied: entrypoints<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (0.4)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (3.7.0)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: gunicorn<22 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (21.2.0)\nRequirement already satisfied: protobuf<6,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from mlflow) (4.25.3)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow) (1.5.3)\nRequirement already satisfied: typing-extensions>=4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.3)\nRequirement already satisfied: urllib3>=1.26.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.1)\nRequirement already satisfied: blinker>=1.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from Flask<4->mlflow) (1.8.2)\nRequirement already satisfied: Werkzeug>=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\nRequirement already satisfied: aniso8601<10,>=8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from graphene<4->mlflow) (9.0.1)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.3)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: zipp>=0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.18.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.1)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (9.4.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.0.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\nRequirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow) (3.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78a2848a-1c64-49fd-ba9f-71018607132a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting spacy\n  Downloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 50.6 MB/s eta 0:00:00\nRequirement already satisfied: packaging>=20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy) (24.0)\nCollecting smart-open<7.0.0,>=5.2.1\n  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.0/57.0 kB 8.9 MB/s eta 0:00:00\nCollecting cymem<2.1.0,>=2.0.2\n  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 7.2 MB/s eta 0:00:00\nCollecting weasel<0.4.0,>=0.1.0\n  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 7.1 MB/s eta 0:00:00\nCollecting catalogue<2.1.0,>=2.0.6\n  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy) (2.31.0)\nCollecting preshed<3.1.0,>=3.0.2\n  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.9/156.9 kB 21.6 MB/s eta 0:00:00\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.1.2)\nCollecting wasabi<1.2.0,>=0.9.1\n  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from spacy) (65.6.3)\nCollecting spacy-loggers<2.0.0,>=1.0.0\n  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\nCollecting thinc<8.3.0,>=8.2.2\n  Downloading thinc-8.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 922.3/922.3 kB 65.1 MB/s eta 0:00:00\nCollecting murmurhash<1.1.0,>=0.28.0\n  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\nCollecting tqdm<5.0.0,>=4.38.0\n  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 12.5 MB/s eta 0:00:00\nCollecting typer<0.10.0,>=0.3.0\n  Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 6.0 MB/s eta 0:00:00\nCollecting srsly<3.0.0,>=2.4.3\n  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 493.0/493.0 kB 37.9 MB/s eta 0:00:00\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy) (2.7.1)\nCollecting spacy-legacy<3.1.0,>=3.0.11\n  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\nCollecting langcodes<4.0.0,>=3.2.0\n  Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 182.0/182.0 kB 25.8 MB/s eta 0:00:00\nRequirement already satisfied: numpy>=1.19.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.23.5)\nCollecting language-data>=1.2\n  Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 98.5 MB/s eta 0:00:00\nRequirement already satisfied: annotated-types>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: typing-extensions>=4.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\nRequirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\nCollecting blis<0.8.0,>=0.7.8\n  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 73.4 MB/s eta 0:00:00\nCollecting confection<1.0.0,>=0.0.1\n  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nCollecting cloudpathlib<0.17.0,>=0.7.0\n  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.0/45.0 kB 7.1 MB/s eta 0:00:00\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\nCollecting marisa-trie>=0.7.7\n  Downloading marisa_trie-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 82.3 MB/s eta 0:00:00\nInstalling collected packages: cymem, wasabi, typer, tqdm, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\nSuccessfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.1.1 murmurhash-1.0.10 preshed-3.0.9 smart-open-6.4.0 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 tqdm-4.66.4 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c76ab97a-7126-4755-8825-c95c6996e24f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/12.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.1/12.8 MB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:04\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/12.8 MB\u001B[0m \u001B[31m65.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m \u001B[32m12.5/12.8 MB\u001B[0m \u001B[31m224.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m216.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m216.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m216.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m65.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\r\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\r\nRequirement already satisfied: numpy>=1.19.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\r\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\nRequirement already satisfied: packaging>=20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\r\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\r\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\r\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\r\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\r\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\r\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\r\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.6.3)\r\nRequirement already satisfied: language-data>=1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\nRequirement already satisfied: annotated-types>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\r\nRequirement already satisfied: typing-extensions>=4.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\r\nRequirement already satisfied: pydantic-core==2.18.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\r\nRequirement already satisfied: certifi>=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\r\nRequirement already satisfied: idna<4,>=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\r\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\r\nRequirement already satisfied: marisa-trie>=0.7.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\r\nInstalling collected packages: en-core-web-sm\r\nSuccessfully installed en-core-web-sm-3.7.1\r\n\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\nYou can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5adff0e2-b418-4521-97bc-9785a0bd582b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be839e23-2702-4c02-ade5-0e2d3112acfe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.metrics.genai import EvaluationExample, make_genai_metric\n",
    "import pandas as pd\n",
    "from databricks_genai_inference import ChatCompletion\n",
    "#import dbdemos\n",
    "# dbdemos.install('llm-rag-chatbot')\n",
    "from databricks.vector_search.client import VectorSearchClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa61220e-d323-4e74-9050-437d7b504a2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import *\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f4e87d7-1e24-4c4f-a201-e5e455259c77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['retailer', 'product_id', 'store_id', 'supplier', 'product', 'product_key', 'upc', 'chain', 'store', 'store_number', 'store_city', 'store_state', 'store_zip', 'store_latitude', 'store_longitude', 'date_key', 'on_hand_quantity', 'id']\n"
     ]
    }
   ],
   "source": [
    "data_inventory_filter = spark.read.table(\"mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2\")\n",
    "print(data_inventory_filter.columns)\n",
    "\n",
    "catalog_name = \"mad_angle\"\n",
    "schema_name = \"default\"\n",
    "source_table_name = \"harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\"\n",
    "source_table_fullname = f\"{catalog_name}.{schema_name}.{source_table_name}\"\n",
    "\n",
    "window = Window.partitionBy().orderBy(data_inventory_filter['on_hand_quantity'].desc())\n",
    "\n",
    "data_inventory_top_100  = spark.read.table(source_table_fullname)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b4b3a78-2721-4a49-ac3f-ac7e42e355d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 0,\n",
    "  \"max_output_tokens\": 8192,\n",
    "}\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130f5f13-742d-4abd-9c61-cd4930019a2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>inputs</th></tr></thead><tbody><tr><td>List(What can be your product recommendation(product,product key) and product information details in the same category to product 3539  in store name ending with 15536 based on inventory available, user)</td></tr><tr><td>List(What is the on hand inventory of product 0995 on 9th July 2022 in store 00128, user)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "What can be your product recommendation(product,product key) and product information details in the same category to product 3539  in store name ending with 15536 based on inventory available",
          "user"
         ]
        ],
        [
         [
          "What is the on hand inventory of product 0995 on 9th July 2022 in store 00128",
          "user"
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "inputs",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"content\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"role\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def get_input_list(dummy_arg):\n",
    "  dummy_arg_list = []\n",
    "  if type(dummy_arg) == list:\n",
    "    dummy_arg_list.append(dummy_arg)\n",
    "  elif type(dummy_arg) == dict:\n",
    "    if dummy_arg.get('inputs'):\n",
    "      dummy_arg_list.append(dummy_arg['inputs'])\n",
    "    else:\n",
    "      dummy_arg_list.append([dummy_arg])\n",
    "  else:\n",
    "    for i in dummy_arg.index:\n",
    "      if type(dummy_arg['inputs'][i]) == list:\n",
    "        tmparg = dummy_arg['inputs'][i]\n",
    "      else:\n",
    "        tmparg = [dummy_arg['inputs'][i]]\n",
    "      dummy_arg_list.append(tmparg)\n",
    "  return dummy_arg_list\n",
    "\n",
    "\n",
    "def dbrxmodel(dummy_arg):\n",
    "  dummy_arg_op_list = []\n",
    "  dummy_arg_in_list = get_input_list(dummy_arg)\n",
    "  for tmparg_ in dummy_arg_in_list:\n",
    "    op = ChatCompletion.create(model=\"databricks-dbrx-instruct\",messages=tmparg_,max_tokens=4096).message\n",
    "    dummy_arg_op_list.append({\"output\":op})\n",
    "  return pd.DataFrame(dummy_arg_op_list)\n",
    "\n",
    "\n",
    "\n",
    "question_list = [\"What can be your product recommendation(product,product key) and product information details in the same category to product 3539  in store name ending with 15536 based on inventory available\",\"What is the on hand inventory of product 0995 on 9th July 2022 in store 00128\"]\n",
    "question_list_new = []\n",
    "for quest in question_list:\n",
    "    question_list_new.append({\"role\": 'user',\"content\":quest})\n",
    "eval_df_dbrx = pd.DataFrame({\"inputs\":question_list_new})\n",
    "\n",
    "display(eval_df_dbrx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3eb34df-bb6d-421b-966c-b46d9a146ad5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Additional Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17dbea55-fdd8-42e4-9925-4ea9f919c808",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, create_map, lit\n",
    "# from itertools import chain\n",
    "\n",
    "# col_list = ['product_key']\n",
    "# for col in col_list:\n",
    "#     unique_list_col = [i[col] for i in data_inventory_top_100.select(col).distinct().collect()]\n",
    "#     print(unique_list_col)\n",
    "#     print(len(unique_list_col))\n",
    "#     dict_label_col = {}\n",
    "#     dict_label_col_sub = {}\n",
    "    \n",
    "#     for  i in range(len(unique_list_col)):\n",
    "#         dict_label_col[str(unique_list_col[i])]= \"Category_\"+str(i%2)\n",
    "       \n",
    "\n",
    "#     print(dict_label_col)\n",
    "#     print(dict_label_col_sub)\n",
    "#     globals()[\"udf_label\"+col] = udf(lambda col: dict_label_col.get(col), StringType())\n",
    "    \n",
    "#     data_inventory_top_100 = data_inventory_top_100.withColumn(\"Category_\"+col,globals()[\"udf_label\"+col](col))\n",
    "   \n",
    " \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c7ec72f-f9df-4ce8-8880-208b01db4962",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# data_inventory_top_100 = data_inventory_top_100.drop('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c13847-b56b-4fb9-9694-30eb67f2dafe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# source_table_name2 = \"harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\"\n",
    "# source_table_fullname2 = f\"{catalog_name}.{schema_name}.{source_table_name2}\"\n",
    "# data_inventory_top_100.write.format(\"delta\").option(\"delta.enableChangeDataFeed\", \"true\").saveAsTable(source_table_fullname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46863070-29a0-4016-a284-3c0e46e07b75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = 'Instructions: Given following SQL schema, records sample & data dictionary, your job is to write ONLY SQL query with proper syntax given a user’s request. Do not join these tables unless absolutely necessary!. Please pick the table for generating query only if the column is present in that table schema. Generate subquery if required to answer complex questions.Also if the user mentions The phrase \"across the years\" it means \"for every year\".The phrase \"across categories\" means \"for every categories\".The phrase \"across retailer level\" means \"for every retailers\".The phrase \"across brand level\" means \"for every brands\".The phrase \"sales uplift\" means \"percentage increase in sales or revenue due to specific promotional activities\".The term \"overall spends\" means \"total spends\".The term \"drainers and drivers\" means \"changes experienced by different brands and pack types over time\".The term \"current period\" refers to the \"latest year in the data\" and \"previous period\" refers to the \"previous years other than latest year in the data\".Whenever you are doing a group by in SQL query make sure to consider that column in the select part of the query has context menu.Whenever you are doing a group by in SQL query make sure to consider that column in the select part of the query.\\\n",
    "Context: Table: mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat \\\n",
    "Columns : `retailer`,`product_id`,`store_id`,`supplier`,`product`,`product_key`,`upc`,`chain`, \\\n",
    "          `store`,`store_number`,`store_city`,`store_state`,`store_zip`,`store_latitude`,\\\n",
    "          `store_longitude`,`date_key`,`on_hand_quantity`,`id`,`Category_product_key`\\\n",
    "Dictionary for mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat : In this context the column \"retailer\" refers to the retailer for example retailer 1, retailer 2,  etc, the column \"product_id\" refers to the product identifier information,the column \"store_id\" refers to the store identifier information, the column \"supplier\" refers to the supplier name,the column \"product\" denotes the name of the product, the column \"product_key\" refers to the product key information,the column \"upc\" represents the universal product code of the product ,  the column \"chain\" represents the retail supermarket chain or banner information,the column \"store\" represents the store information, the column \"store_number\" represents the store identifier,the column \"store_city\" is  name of the city in which store exists,the column \"store_state\" is  name of the state in which store exists ,the column \"store_zip\" is   zipcode of the city in which store exists ,the column \"store_latitude\" is  latitude information of the store ,the column \"store_longitude\" is  longitude information of the store ,the column \"date_key\" is  date in which the information was collected, the column \"on_hand_quantity\" is  the on hand quantity of the inventory available in the store for that particular product , the column \"id\" is  the identifier denoting the unique  combination of product store information in a store, the column \"Category_product_key\" is  the identifier denoting the category of product information in a store\\\n",
    "Data for mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat: \\\n",
    "1 | `RETAILER 6`,8699263674839736531,521626801377406987,`SUPPLIER 06`,`PRODUCT 4836`,`4836`,`0000000004836`,`RETAILER 6`,`STORE 30469`,`04731`,`CITY 09257`,`SC`,`29203`,34.1,-81.04,`2022-07-13`,11211,`86992636748397365315216268013774069872022-07-13`,`Category_0`\\\n",
    "2 | `RETAILER 6`,8699263674839736531,521626801377406987,`SUPPLIER 06`,`PRODUCT 4836`,`4836`,`0000000004836`,`RETAILER 6`,`STORE 30469`,`04731`,`CITY 09257`,`SC`,`29203`,34.1,-81.04,`2022-06-07`,11950,\t`86992636748397365315216268013774069872022-06-07`,`Category_0`\\\n",
    "3 | `RETAILER 4`,5373936945841831885,45926792719034451,`SUPPLIER 06`,`PRODUCT 5516`,`5516`,`000000000551`,`RETAILER 4`,`STORE 0564`,`0029`,`CITY 02294`,`NJ`,`0801`,39.82,-75.35,`2022-08-28`,188,`5373936945841831885459267927190344512022-08-28`,`Category_1`\\\n",
    "4 | `RETAILER 4`,3493016077731501006,2544351317611134725,`SUPPLIER 06`,`PRODUCT 5051`,`5051`,`0000000005051`,`RETAILER 4`,`STORE 11522`,`00659`,`CITY 32007`,`OR`,`97321`,44.65,-123.14,`2022-08-28`,48,`349301607773150100625443513176111347252022-08-28`,`Category_1`\\\n",
    "5 | `RETAILER 4`,860960474656778313,2544351317611134725,`SUPPLIER 06`,`PRODUCT 4994`,`4994`,`0000000004994`,`RETAILER 4`,`STORE 11522`,`00659`,`CITY 32007`,`OR`,`97321`,44.65,-123.14,`2022-08-28`,23,\t`86096047465677831325443513176111347252022-08-28`,`Category_1`'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a879d4-ce59-4adb-86bc-8f7ea196b2fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32e7a52f-ed42-4c66-92c3-e123d32da621",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/06 23:16:34 INFO mlflow.tracking.fluent: Experiment with name '/Workspace/Shared/Mad Angle /mlflow_experiments/dbrx_solution_prototype_v33' does not exist. Creating a new experiment.\n2024/05/06 23:16:41 WARNING mlflow.utils.requirements_utils: Failed to run predict on input_example, dependencies introduced in predict are not captured.\nPySparkRuntimeError()Traceback (most recent call last):\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/utils/_capture_modules.py\", line 135, in _load_pyfunc_patch\n    model.predict(input_example, params=params)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/pyfunc/model.py\", line 543, in predict\n    return self.python_model.predict(\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/pyfunc/model.py\", line 162, in predict\n    return self.func(model_input)\n\n\n  File \"/home/spark-baecf587-f692-4ed4-bd68-2d/.ipykernel/37427/command-191870854588994-1369309507\", line 24, in dbrxmodel\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks_genai_inference/api/chat_completion.py\", line 48, in create\n    return super().create(**kwargs)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks_genai_inference/api/abstract/foundation_model_api_resource.py\", line 98, in create\n    return cls._make_query(client, api_input, endpoint)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks_genai_inference/api/abstract/foundation_model_api_resource.py\", line 140, in _make_query\n    w = WorkspaceClient()\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks/sdk/__init__.py\", line 146, in __init__\n    self._dbutils = _make_dbutils(self._config)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks/sdk/__init__.py\", line 86, in _make_dbutils\n    from databricks.sdk.runtime import dbutils as runtime_dbutils\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/utils/_capture_modules.py\", line 49, in wrapper\n    return original(name, globals, locals, fromlist, level)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks/sdk/runtime/__init__.py\", line 81, in <module>\n    userNamespaceGlobals = UserNamespaceInitializer.getOrCreate().get_namespace_globals()\n\n\n  File \"/databricks/python_shell/dbruntime/UserNamespaceInitializer.py\", line 100, in getOrCreate\n    sparkHandles, spark_entry_point = initialize_spark_connection(is_pinn_mode_enabled())\n\n\n  File \"/databricks/python_shell/dbruntime/spark_connection.py\", line 197, in initialize_spark_connection\n    sc = RemoteContext(gateway=gateway, conf=conf)\n\n\n  File \"/databricks/spark/python/pyspark/context.py\", line 189, in __init__\n    raise PySparkRuntimeError(\n\n\npyspark.errors.exceptions.base.PySparkRuntimeError: [CONTEXT_UNAVAILABLE_FOR_REMOTE_CLIENT] Remote client cannot create a SparkContext. Create SparkSession instead.\n2024/05/06 23:16:41 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.12.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7cd40d4dff4eb89d39f086d9c4c445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/06 23:16:41 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562e3cd9013e40539427f818b8cf8dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/06 23:16:43 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n2024/05/06 23:16:44 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/05/06 23:16:44 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/05/06 23:16:48 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/05/06 23:16:48 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n2024/05/06 23:16:48 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'flesch_kincaid_grade_level' because it returned None.\n2024/05/06 23:16:48 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'ari_grade_level' because it returned None.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'exact_match' because it returned None.\n2024/05/06 23:16:48 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n2024/05/06 23:16:48 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'flesch_kincaid_grade_level' because it returned None.\n2024/05/06 23:16:48 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'ari_grade_level' because it returned None.\n2024/05/06 23:16:48 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'exact_match' because it returned None.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0cf7fb64794d10b0db87ee85e44469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/06 23:16:50 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### output from DBRX #####################\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>output</th></tr></thead><tbody><tr><td>Here is the SQL query to get the product recommendation and product information details in the same category as product 3539 in the store with a name ending with 15536, based on the inventory available:\n",
       "```vbnet\n",
       "SELECT product, product_key, supplier, on_hand_quantity\n",
       "FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n",
       "WHERE Category_product_key = (\n",
       "  SELECT Category_product_key\n",
       "  FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n",
       "  WHERE product_key = '3539' AND store LIKE '%15536'\n",
       ") AND store LIKE '%15536' AND product_key!= '3539'\n",
       "ORDER BY on_hand_quantity DESC\n",
       "LIMIT 5;\n",
       "```\n",
       "This query will return the top 5 products in the same category as product 3539 with the highest on-hand quantity in the store with a name ending with 15536, excluding product 3539 itself. The result will include the product name, product key, supplier, and on-hand quantity.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Here is the SQL query to get the product recommendation and product information details in the same category as product 3539 in the store with a name ending with 15536, based on the inventory available:\n```vbnet\nSELECT product, product_key, supplier, on_hand_quantity\nFROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\nWHERE Category_product_key = (\n  SELECT Category_product_key\n  FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n  WHERE product_key = '3539' AND store LIKE '%15536'\n) AND store LIKE '%15536' AND product_key!= '3539'\nORDER BY on_hand_quantity DESC\nLIMIT 5;\n```\nThis query will return the top 5 products in the same category as product 3539 with the highest on-hand quantity in the store with a name ending with 15536, excluding product 3539 itself. The result will include the product name, product key, supplier, and on-hand quantity."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "output",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-baecf587-f692-4ed4-bd68-2d/.ipykernel/37427/command-191870854589094-786705813:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  pred_dbx_final = pred_dbx_final.append(pred_dbrx)\n2024/05/06 23:16:58 WARNING mlflow.utils.requirements_utils: Failed to run predict on input_example, dependencies introduced in predict are not captured.\nPySparkRuntimeError()Traceback (most recent call last):\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/utils/_capture_modules.py\", line 135, in _load_pyfunc_patch\n    model.predict(input_example, params=params)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/pyfunc/model.py\", line 543, in predict\n    return self.python_model.predict(\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/pyfunc/model.py\", line 162, in predict\n    return self.func(model_input)\n\n\n  File \"/home/spark-baecf587-f692-4ed4-bd68-2d/.ipykernel/37427/command-191870854588994-1369309507\", line 24, in dbrxmodel\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks_genai_inference/api/chat_completion.py\", line 48, in create\n    return super().create(**kwargs)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks_genai_inference/api/abstract/foundation_model_api_resource.py\", line 98, in create\n    return cls._make_query(client, api_input, endpoint)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks_genai_inference/api/abstract/foundation_model_api_resource.py\", line 140, in _make_query\n    w = WorkspaceClient()\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks/sdk/__init__.py\", line 146, in __init__\n    self._dbutils = _make_dbutils(self._config)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks/sdk/__init__.py\", line 86, in _make_dbutils\n    from databricks.sdk.runtime import dbutils as runtime_dbutils\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/mlflow/utils/_capture_modules.py\", line 49, in wrapper\n    return original(name, globals, locals, fromlist, level)\n\n\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-baecf587-f692-4ed4-bd68-2da6de781a56/lib/python3.10/site-packages/databricks/sdk/runtime/__init__.py\", line 81, in <module>\n    userNamespaceGlobals = UserNamespaceInitializer.getOrCreate().get_namespace_globals()\n\n\n  File \"/databricks/python_shell/dbruntime/UserNamespaceInitializer.py\", line 100, in getOrCreate\n    sparkHandles, spark_entry_point = initialize_spark_connection(is_pinn_mode_enabled())\n\n\n  File \"/databricks/python_shell/dbruntime/spark_connection.py\", line 197, in initialize_spark_connection\n    sc = RemoteContext(gateway=gateway, conf=conf)\n\n\n  File \"/databricks/spark/python/pyspark/context.py\", line 189, in __init__\n    raise PySparkRuntimeError(\n\n\npyspark.errors.exceptions.base.PySparkRuntimeError: [CONTEXT_UNAVAILABLE_FOR_REMOTE_CLIENT] Remote client cannot create a SparkContext. Create SparkSession instead.\n2024/05/06 23:16:58 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.12.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2026be39f6a643189be5fdfccf5fd278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/06 23:16:58 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86085c962a144af09055f3ba9da77d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/06 23:17:00 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n2024/05/06 23:17:01 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2024/05/06 23:17:01 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2024/05/06 23:17:04 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2024/05/06 23:17:04 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n2024/05/06 23:17:04 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'flesch_kincaid_grade_level' because it returned None.\n2024/05/06 23:17:04 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'ari_grade_level' because it returned None.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'exact_match' because it returned None.\n2024/05/06 23:17:04 WARNING mlflow.metrics.metric_definitions: Failed to load 'toxicity' metric (error: ModuleNotFoundError(\"No module named 'evaluate'\")), skipping metric logging.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'toxicity' because it returned None.\n2024/05/06 23:17:04 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for flesch kincaid metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'flesch_kincaid_grade_level' because it returned None.\n2024/05/06 23:17:04 WARNING mlflow.metrics.metric_definitions: Failed to import textstat for automated readability index metric, skipping metric logging. Please install textstat using 'pip install textstat'.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'ari_grade_level' because it returned None.\n2024/05/06 23:17:04 WARNING mlflow.models.evaluation.default_evaluator: Did not log builtin metric 'exact_match' because it returned None.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa403e4c876429e85a6b3ef50fc55d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/06 23:17:06 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### output from DBRX #####################\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>output</th></tr></thead><tbody><tr><td>Here is the SQL query to get the on-hand inventory of product 0995 on 9th July 2022 in store 00128:\n",
       "\n",
       "```\n",
       "SELECT on_hand_quantity\n",
       "FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n",
       "WHERE product_key = '0995' AND store_number = '00128' AND date_key = '2022-07-09';\n",
       "```\n",
       "\n",
       "This query selects the `on_hand_quantity` column from the `mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat` table, and filters the results to only include rows where the `product_key` is '0995', the `store_number` is '00128', and the `date_key` is '2022-07-09'. This should give you the on-hand inventory of product 0995 on 9th July 2022 in store 00128.\n",
       "\n",
       "Note: The `product_key` column in the table schema is used to refer to the product identifier information, and the `store_number` column is used to refer to the store identifier information. The `date_key` column is used to refer to the date in which the information was collected. The `on_hand_quantity` column is used to refer to the on-hand quantity of the inventory available in the store for that particular product.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Here is the SQL query to get the on-hand inventory of product 0995 on 9th July 2022 in store 00128:\n\n```\nSELECT on_hand_quantity\nFROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\nWHERE product_key = '0995' AND store_number = '00128' AND date_key = '2022-07-09';\n```\n\nThis query selects the `on_hand_quantity` column from the `mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat` table, and filters the results to only include rows where the `product_key` is '0995', the `store_number` is '00128', and the `date_key` is '2022-07-09'. This should give you the on-hand inventory of product 0995 on 9th July 2022 in store 00128.\n\nNote: The `product_key` column in the table schema is used to refer to the product identifier information, and the `store_number` column is used to refer to the store identifier information. The `date_key` column is used to refer to the date in which the information was collected. The `on_hand_quantity` column is used to refer to the on-hand quantity of the inventory available in the store for that particular product."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "output",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-baecf587-f692-4ed4-bd68-2d/.ipykernel/37427/command-191870854589094-786705813:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  pred_dbx_final = pred_dbx_final.append(pred_dbrx)\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/Workspace/Shared/Mad Angle /mlflow_experiments/dbrx_solution_prototype_v33\")\n",
    "i=0\n",
    "pred_dbx_final = pd.DataFrame([])\n",
    "while i< eval_df_dbrx.shape[0]:\n",
    "    with mlflow.start_run(run_name='log_dbrx_model'):\n",
    "        dbrx_model_info = mlflow.pyfunc.log_model(artifact_path='dbrx_model',python_model=dbrxmodel,\n",
    "                                                #signature=signature_dbrx,\n",
    "                                                input_example=pd.DataFrame({'inputs':[{\"role\": \"system\",\"content\": f\"{system_prompt}\"},\n",
    "                                                                eval_df_dbrx['inputs'].iloc[i]]})\n",
    "                                                )\n",
    "        results = mlflow.evaluate(model=dbrx_model_info.model_uri,data=eval_df_dbrx,\n",
    "                            model_type=\"question-answering\",\n",
    "                            evaluators=\"default\",\n",
    "                            #   extra_metrics=[\n",
    "                            #       answer_accessibility\n",
    "                            #       ],\n",
    "                                )\n",
    "    dbrx_model = mlflow.pyfunc.load_model(dbrx_model_info.model_uri)\n",
    "\n",
    "    pred_dbrx = dbrx_model.predict({'inputs':[{\"role\": \"system\",\"content\": f\"{system_prompt}\"},\n",
    "                                                                eval_df_dbrx['inputs'].iloc[i]]})\n",
    "    print('##################### output from DBRX #####################\\n')\n",
    "    display(pred_dbrx)\n",
    "    pred_dbx_final = pred_dbx_final.append(pred_dbrx)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b1c15e-4469-45a9-add6-7435b902dba2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>output</th></tr></thead><tbody><tr><td>Here is the SQL query to get the product recommendation and product information details in the same category as product 3539 in the store with a name ending with 15536, based on the inventory available:\n",
       "```vbnet\n",
       "SELECT product, product_key, supplier, on_hand_quantity\n",
       "FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n",
       "WHERE Category_product_key = (\n",
       "  SELECT Category_product_key\n",
       "  FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n",
       "  WHERE product_key = '3539' AND store LIKE '%15536'\n",
       ") AND store LIKE '%15536' AND product_key!= '3539'\n",
       "ORDER BY on_hand_quantity DESC\n",
       "LIMIT 5;\n",
       "```\n",
       "This query will return the top 5 products in the same category as product 3539 with the highest on-hand quantity in the store with a name ending with 15536, excluding product 3539 itself. The result will include the product name, product key, supplier, and on-hand quantity.</td></tr><tr><td>Here is the SQL query to get the on-hand inventory of product 0995 on 9th July 2022 in store 00128:\n",
       "\n",
       "```\n",
       "SELECT on_hand_quantity\n",
       "FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n",
       "WHERE product_key = '0995' AND store_number = '00128' AND date_key = '2022-07-09';\n",
       "```\n",
       "\n",
       "This query selects the `on_hand_quantity` column from the `mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat` table, and filters the results to only include rows where the `product_key` is '0995', the `store_number` is '00128', and the `date_key` is '2022-07-09'. This should give you the on-hand inventory of product 0995 on 9th July 2022 in store 00128.\n",
       "\n",
       "Note: The `product_key` column in the table schema is used to refer to the product identifier information, and the `store_number` column is used to refer to the store identifier information. The `date_key` column is used to refer to the date in which the information was collected. The `on_hand_quantity` column is used to refer to the on-hand quantity of the inventory available in the store for that particular product.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Here is the SQL query to get the product recommendation and product information details in the same category as product 3539 in the store with a name ending with 15536, based on the inventory available:\n```vbnet\nSELECT product, product_key, supplier, on_hand_quantity\nFROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\nWHERE Category_product_key = (\n  SELECT Category_product_key\n  FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\n  WHERE product_key = '3539' AND store LIKE '%15536'\n) AND store LIKE '%15536' AND product_key!= '3539'\nORDER BY on_hand_quantity DESC\nLIMIT 5;\n```\nThis query will return the top 5 products in the same category as product 3539 with the highest on-hand quantity in the store with a name ending with 15536, excluding product 3539 itself. The result will include the product name, product key, supplier, and on-hand quantity."
        ],
        [
         "Here is the SQL query to get the on-hand inventory of product 0995 on 9th July 2022 in store 00128:\n\n```\nSELECT on_hand_quantity\nFROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat\nWHERE product_key = '0995' AND store_number = '00128' AND date_key = '2022-07-09';\n```\n\nThis query selects the `on_hand_quantity` column from the `mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat` table, and filters the results to only include rows where the `product_key` is '0995', the `store_number` is '00128', and the `date_key` is '2022-07-09'. This should give you the on-hand inventory of product 0995 on 9th July 2022 in store 00128.\n\nNote: The `product_key` column in the table schema is used to refer to the product identifier information, and the `store_number` column is used to refer to the store identifier information. The `date_key` column is used to refer to the date in which the information was collected. The `on_hand_quantity` column is used to refer to the on-hand quantity of the inventory available in the store for that particular product."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "output",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dbx_final.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d8eb3e-0c28-4880-885b-850c1cb89ded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted SQL Query:\n SELECT product, product_key, supplier, on_hand_quantity FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat WHERE Category_product_key = (   SELECT Category_product_key   FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat   WHERE product_key = '3539' AND store LIKE '%15536' ) AND store LIKE '%15536' AND product_key!= '3539' ORDER BY on_hand_quantity DESC LIMIT 5\n+------------+-----------+-----------+----------------+\n|     product|product_key|   supplier|on_hand_quantity|\n+------------+-----------+-----------+----------------+\n|PRODUCT 0160|       0160|SUPPLIER 06|         15150.0|\n|PRODUCT 0160|       0160|SUPPLIER 06|         13485.0|\n+------------+-----------+-----------+----------------+\n\nExtracted SQL Query:\nSELECT on_hand_quantity FROM mad_angle.default.harmonized_retailer_inventory_store_delta_filter_with_id2_top100_with_cat WHERE product_key = '0995' AND store_number = '00128' AND date_key = '2022-07-09'\n+----------------+\n|on_hand_quantity|\n+----------------+\n|         15723.0|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while i<pred_dbx_final.shape[0]:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(pred_dbx_final['output'].iloc[i])\n",
    "    sql_pattern =  r\"```(.*?)```|(SELECT(.*?);)\"\n",
    "    matches = re.search(sql_pattern, doc.text,re.DOTALL)\n",
    "    try:\n",
    "            sql_query = matches.group(1).strip()\n",
    "            sql_query = sql_query.replace(\"\\n\",\" \")\n",
    "            sql_query = sql_query.replace(\";\",\"\")\n",
    "            sql_query = sql_query.removeprefix(\"vbnet\")\n",
    "            sql_query = sql_query.removeprefix(\"sql\")\n",
    "            print(\"Extracted SQL Query:\")\n",
    "            print(sql_query)\n",
    "    except:\n",
    "                print(\"No SQL query found in the text.\")\n",
    "\n",
    "    # Using PySpark to execute the SQL query\n",
    "    df = spark.sql(sql_query)\n",
    "\n",
    "    # Show the results\n",
    "    df.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81ef63cc-a45f-4c46-a3cb-b6bdc5f8cbdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from pyspark.sql.functions import struct, col \n",
    "logged_model = 'runs:/247e266185b5478283c0468f7bdd77e4/dbrx_model' \n",
    "# Load model as a Spark UDF. \n",
    "# loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model) \n",
    "#  Predict on a Spark DataFrame. df.withColumn('predictions', loaded_model(struct(*map(col, df.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bedc1c4-c0ca-4802-a0c7-03204911ebd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73526444-8550-465e-8ff1-2d26b45f6403",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af0aef50-d74b-4f29-8cd3-720f3433ae09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## show me the on hand quantity of product starting/ending with 3563 on 2022-11-30 and STORE 00076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a53b2fd-8c06-4624-9620-7316c44304ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Attributes of every product - it comes under category, price point , disposition, size/quantity ...etc\n",
    "# Allied products - recommend  500 ml  instead of 2 250 ml either we dont have 250 ml sufficient quantity / see if we can conceive this opportunity to increase the share of wallet\n",
    "# complimentary products - recommend bread and butter together - we need LLM to suggest these\n",
    "\n",
    "## customer is very loyal to Manufacturer , so in recommendation , the products from Manufacturer either allied - optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "451757b2-fd10-4282-b329-edc3f07b43b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Solution_initial_prototype_final",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
